# -*- coding: utf-8 -*-
"""IS_SEM_PROJECT_2019_MC_13.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1m8AQwgF65Ke904CoyHBVkTmMRSrLmzZR

## **IMPORTING LIBRARIES**
"""

import tensorflow as tf
import keras
from keras import Sequential,layers
from keras.layers import InputLayer, Dense, Conv2D, MaxPooling2D, Dropout , Flatten,Activation, AveragePooling2D, MaxPool2D
from keras.optimizers import Adam
import numpy as np
from PIL import Image
import matplotlib.pyplot as plt
from keras.utils import to_categorical
!pip install keras_tuner -q
import keras_tuner as kt
import os
from sklearn.model_selection import train_test_split
from google.colab import drive

"""## **DATASET AQUISITION**
(From Google Drive)
"""

drive.mount('/content/drive')
Classes=['Ali', 'Asad', 'Dawood Imtiaz', 'Distayy', 'Haseeb', 'Shaheer', 'SHAHWAR', 'Ume Habiba', 'Usman Tariq', 'Yusra']
Class_Length=len(Classes)

"""## **DATASET RESIZING**
(According of Respective Architectures)
"""

def data_resize(image_height,image_width, channel):
  objects=['Ali', 'Asad', 'Dawood Imtiaz', 'Distayy', 'Haseeb', 'Shaheer', 'SHAHWAR', 'Ume Habiba', 'Usman Tariq', 'Yusra']
  num_images=500
  num_objects=10
  images = np.zeros((num_images, image_width, image_height, channel), dtype=np.uint8)
  labels = np.zeros((num_images, ), dtype=np.uint8)
  i=0
  for obj in range(num_objects):
    j=0
    obj_dir = f"/content/drive/MyDrive/dataset/{objects[obj]}"
    for filename in os.listdir(obj_dir):
      img = Image.open(os.path.join(obj_dir, filename))
      img = img.resize((image_width, image_height))
      images[i*50 + j] = np.array(img)
      labels[i*50 + j] = i
      j+=1
    i+=1
  return images,labels

"""# **ALEXNET**
(227x227x3)

(IMPLEMENTATION / PERFORMANCE ANALYSIS)
"""

Alex_Images, Alex_Label = data_resize(227,227,3)
Alex_X_Train, Alex_X_Test, Alex_Y_Train, Alex_Y_Test =  train_test_split(Alex_Images,Alex_Label,test_size=0.2,random_state=1)

Alex_X_Train=Alex_X_Train.astype('float32')/255.0
Alex_X_Test=Alex_X_Test.astype('float32')/255.0

Alex_Y_Train=to_categorical(Alex_Y_Train,Class_Length)
Alex_Y_Test=to_categorical(Alex_Y_Test,Class_Length)
print(Alex_Y_Train.shape)

model = Sequential()
model.add(Conv2D(filters=96, input_shape=(227,227,3), kernel_size=(11,11), strides=(4,4), padding='valid',activation='relu',name='Conv_1'))
model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid',name='MaxPool2D_1'))
model.add(Conv2D(filters=256, kernel_size=(11,11), strides=(1,1), padding='valid',activation='relu',name='Conv_2'))
model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid',name='MaxPool2D_2'))
model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid',activation='relu',name='Conv_3'))
model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid',activation='relu',name='Conv_4'))
model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='valid',activation='relu',name='Conv_5'))
model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid',name='MaxPool2D_3'))
model.add(Flatten())
model.add(Dense(9216, input_shape=(150*150*3,),activation='relu',name='FC_Layer1'))
model.add(Dropout(0.4))
model.add(Dense(4096,activation='relu',name='FC_Layer2'))
model.add(Dropout(0.4))
model.add(Dense(4096,activation='relu',name='FC_Layer3'))
model.add(Dropout(0.4))
model.add(Dense(1000,activation='relu',name='Out_Layer'))
model.add(Dense(10,activation='softmax',name='Out_Layer_2'))
model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001),loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])
model.summary()

model.fit(Alex_X_Train,Alex_Y_Train,validation_split=0.2,epochs=10,shuffle=True)

a,b=model.evaluate(Alex_X_Test,Alex_Y_Test)
print(f'LOSS : {a}\nACCURACY : {b}')

y_pred=model.predict(Alex_X_Test)
plt.figure(figsize=(35,35))
for i in range(100):
  plt.subplot(10,10,i+1)
  plt.imshow(Alex_X_Test[i])
  plt.title(Classes[np.argmax(y_pred[i])])
  plt.xticks([])
  plt.yticks([])

"""# **LENET-5**
(32x32x1)

(IMPLEMENTATION / PERFORMANCE ANALYSIS)
"""

Lenet_Images, Lenet_Label = data_resize(32,32,3)
Lenet_X_Train, Lenet_X_Test, Lenet_Y_Train, Lenet_Y_Test =  train_test_split(Lenet_Images,Lenet_Label,test_size=0.2,random_state=1)

Lenet_X_Train1=Lenet_X_Train.astype('float32')/255.0
Lenet_X_Test1=Lenet_X_Test.astype('float32')/255.0

Lnt_Y_Train=to_categorical(Lenet_Y_Train,Class_Length)
Lnt_Y_Test=to_categorical(Lenet_Y_Test,Class_Length)
x_train_gray = np.dot(Lenet_X_Train, [0.2989, 0.5870, 0.1140])
x_test_gray = np.dot(Lenet_X_Test, [0.2989, 0.5870, 0.1140])
Lnt_X_Train = x_train_gray.reshape(x_train_gray.shape[0], 32, 32, 1)
Lnt_X_Test = x_test_gray.reshape(x_test_gray.shape[0], 32, 32, 1)

Lenet_Model=Sequential()
Lenet_Model.add(Conv2D(filters=6, input_shape=(32,32,1), kernel_size=(5,5), strides=(1,1), padding='valid',activation='relu',name='Conv_1'))
Lenet_Model.add(AveragePooling2D(pool_size=(2,2), strides=(2,2), padding='valid',name='MaxPool2D_1'))
Lenet_Model.add(Conv2D(filters=16, kernel_size=(5,5), strides=(1,1), padding='valid',activation='relu',name='Conv_2'))
Lenet_Model.add(AveragePooling2D(pool_size=(2,2), strides=(2,2), padding='valid',name='MaxPool2D_2'))
Lenet_Model.add(Flatten(name='Flat_1'))
Lenet_Model.add(Dense(120,activation='relu',name='FC_1'))
Lenet_Model.add(Dense(84,activation='relu',name='FC_2'))
Lenet_Model.add(Dense(10,activation='softmax',name='Our_Layer'))
Lenet_Model.summary()

Lenet_Model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy'])

Lenet_Model.fit(Lnt_X_Train,Lnt_Y_Train,validation_split=0.2,epochs=10,shuffle=True)

c,d=Lenet_Model.evaluate(Lnt_X_Test,Lnt_Y_Test)
print(f'LOSS : {c}\nACCURACY : {d}')

"""

# **VGG-16**
(224x224x3)

(IMPLEMENTATION / PERFORMANCE ANALYSIS)"""

Vgg_Images, Vgg_Label = data_resize(224,224,3)
Vgg_X_Train, Vgg_X_Test, Vgg_Y_Train, Vgg_Y_Test =  train_test_split(Vgg_Images,Vgg_Label,test_size=0.2,random_state=1)

Vgg_X_Train=Vgg_X_Train.astype('float32')/255.0
Vgg_X_Test=Vgg_X_Test.astype('float32')/255.0
print()

Vgg_Y_Train=to_categorical(Vgg_Y_Train,Class_Length)
Vgg_Y_Test=to_categorical(Vgg_Y_Test,Class_Length)

model1 = Sequential()
model1.add(Conv2D(input_shape=(224,224,3),filters=64,kernel_size=(3,3),padding="valid", activation="relu"))
model1.add(Conv2D(filters=64,kernel_size=(3,3),padding="valid", activation="relu"))
model1.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))
model1.add(Conv2D(filters=128, kernel_size=(3,3), padding="valid", activation="relu"))
model1.add(Conv2D(filters=128, kernel_size=(3,3), padding="valid", activation="relu"))
model1.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))
model1.add(Conv2D(filters=256, kernel_size=(3,3), padding="valid", activation="relu"))
model1.add(Conv2D(filters=256, kernel_size=(3,3), padding="valid", activation="relu"))
model1.add(Conv2D(filters=256, kernel_size=(3,3), padding="valid", activation="relu"))
model1.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))
model1.add(Conv2D(filters=512, kernel_size=(3,3), padding="valid", activation="relu"))
model1.add(Conv2D(filters=512, kernel_size=(3,3), padding="valid", activation="relu"))
model1.add(Conv2D(filters=512, kernel_size=(3,3), padding="valid", activation="relu"))
model1.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))
model1.add(Conv2D(filters=512, kernel_size=(3,3), padding="valid", activation="relu"))
model1.add(Conv2D(filters=512, kernel_size=(3,3), padding="valid", activation="relu"))
model1.add(Conv2D(filters=512, kernel_size=(3,3), padding="valid", activation="relu"))
model1.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))
model1.add(Flatten())
model1.add(Dense(units=4096,activation="relu"))
model1.add(Dense(units=4096,activation="relu"))
model1.add(Dense(units=10, activation="softmax"))
model1.compile(optimizer=Adam(learning_rate=0.001), loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])

model1.fit(Vgg_X_Train,Vgg_Y_Train,validation_split=0.2,epochs=10,shuffle=True)

e,f=model1.evaluate(Vgg_X_Test,Vgg_Y_Test)
print(f'LOSS : {e}\nACCURACY : {f}')

"""# **MI-NET-8**
(48x48x3)

(CNN DESIGN PROJECT)
"""

MI_Images, MI_Label = data_resize(48,48,3)
MI_X_Train, MI_X_Test, MI_Y_Train, MI_Y_Test =  train_test_split(MI_Images, MI_Label, test_size=0.2, random_state=1)

MI_X_Train = MI_X_Train.astype('float32')/255.0
MI_X_Test = MI_X_Test.astype('float32')/255.0
MI_Y_Train=to_categorical(MI_Y_Train,Class_Length)
MI_Y_Test=to_categorical(MI_Y_Test,Class_Length)

def model_Builder(hp):
  model3 = Sequential()
  hp_Model=hp.Choice('Model_no',values=[1,2,3,4,5])
  if hp_Model == 1:
    model3.add(Conv2D(filters=30, input_shape=(48,48,3), kernel_size=(3,3), strides=(2,2), padding='valid',activation='relu',name='Conv_1'))
    model3.add(MaxPooling2D(pool_size=(2,2), strides=(1,1), padding='valid',name='MaxPool2D_1'))
    model3.add(Conv2D(filters=50, kernel_size=(3,3), strides=(1,1), padding='valid',activation='relu',name='Conv_2'))
    model3.add(MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='valid',name='MaxPool2D_2'))
    model3.add(Conv2D(filters=70, kernel_size=(3,3), strides=(1,1), padding='valid',activation='relu',name='Conv_3'))
    model3.add(Conv2D(filters=70, kernel_size=(3,3), strides=(1,1), padding='valid',activation='relu',name='Conv_4'))
    model3.add(Conv2D(filters=50, kernel_size=(3,3), strides=(1,1), padding='valid',activation='relu',name='Conv_5'))
    model3.add(MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='valid',name='MaxPool2D_3'))
  if hp_Model == 2:
    model3.add(Conv2D(filters=70, input_shape=(48,48,3), kernel_size=(7,7), strides=(2,2), padding='valid',activation='relu',name='Conv_1'))
    model3.add(MaxPooling2D(pool_size=(2,2), strides=(1,1), padding='valid',name='MaxPool2D_1'))
    model3.add(Conv2D(filters=100, kernel_size=(5,5), strides=(1,1), padding='same',activation='relu',name='Conv_2'))
    model3.add(MaxPooling2D(pool_size=(2,2), strides=(1,1), padding='valid',name='MaxPool2D_2'))
    model3.add(Conv2D(filters=150, kernel_size=(3,3), strides=(1,1), padding='valid',activation='relu',name='Conv_3'))
    model3.add(Conv2D(filters=150, kernel_size=(3,3), strides=(1,1), padding='valid',activation='relu',name='Conv_4'))
    model3.add(Conv2D(filters=100, kernel_size=(3,3), strides=(1,1), padding='valid',activation='relu',name='Conv_5'))
    model3.add(MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='valid',name='MaxPool2D_3'))
  if hp_Model == 3:
    model3.add(Conv2D(filters=70, input_shape=(48,48,3), kernel_size=(3,3), strides=(2,2), padding='valid',activation='relu',name='Conv_1'))
    model3.add(MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same',name='MaxPool2D_1'))
    model3.add(Conv2D(filters=100, kernel_size=(5,5), strides=(1,1), padding='valid',activation='relu',name='Conv_2'))
    model3.add(MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='valid',name='MaxPool2D_2'))
    model3.add(Conv2D(filters=150, kernel_size=(3,3), strides=(1,1), padding='valid',activation='relu',name='Conv_3'))
    model3.add(Conv2D(filters=150, kernel_size=(3,3), strides=(1,1), padding='valid',activation='relu',name='Conv_4'))
    model3.add(Conv2D(filters=100, kernel_size=(3,3), strides=(1,1), padding='same',activation='relu',name='Conv_5'))
    model3.add(MaxPooling2D(pool_size=(2,2), strides=(1,1), padding='valid',name='MaxPool2D_3'))
  if hp_Model == 4:
    model3.add(Conv2D(filters=50, input_shape=(48,48,3), kernel_size=(7,7), strides=(2,2), padding='valid',activation='relu',name='Conv_1'))
    model3.add(MaxPooling2D(pool_size=(2,2), strides=(1,1), padding='valid',name='MaxPool2D_1'))
    model3.add(Conv2D(filters=70, kernel_size=(5,5), strides=(1,1), padding='same',activation='relu',name='Conv_2'))
    model3.add(MaxPooling2D(pool_size=(2,2), strides=(1,1), padding='valid',name='MaxPool2D_2'))
    model3.add(Conv2D(filters=100, kernel_size=(3,3), strides=(1,1), padding='valid',activation='relu',name='Conv_3'))
    model3.add(Conv2D(filters=100, kernel_size=(3,3), strides=(1,1), padding='valid',activation='relu',name='Conv_4'))
    model3.add(Conv2D(filters=70, kernel_size=(3,3), strides=(1,1), padding='valid',activation='relu',name='Conv_5'))
    model3.add(MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='valid',name='MaxPool2D_3'))
  if hp_Model == 5:
    model3.add(Conv2D(filters=150, input_shape=(48,48,3), kernel_size=(7,7), strides=(2,2), padding='valid',activation='relu',name='Conv_1'))
    model3.add(MaxPooling2D(pool_size=(2,2), strides=(1,1), padding='valid',name='MaxPool2D_1'))
    model3.add(Conv2D(filters=200, kernel_size=(5,5), strides=(1,1), padding='same',activation='relu',name='Conv_2'))
    model3.add(MaxPooling2D(pool_size=(2,2), strides=(1,1), padding='valid',name='MaxPool2D_2'))
    model3.add(Conv2D(filters=250, kernel_size=(3,3), strides=(1,1), padding='valid',activation='relu',name='Conv_3'))
    model3.add(Conv2D(filters=250, kernel_size=(3,3), strides=(1,1), padding='valid',activation='relu',name='Conv_4'))
    model3.add(Conv2D(filters=200, kernel_size=(3,3), strides=(1,1), padding='valid',activation='relu',name='Conv_5'))
    model3.add(MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='valid',name='MaxPool2D_3'))
  model3.add(Flatten())
  model3.add(Dense(4096, input_shape=(150*150*3,),activation='relu',name='FC_Layer1'))
  model3.add(Dropout(0.4))
  model3.add(Dense(4096,activation='relu',name='FC_Layer2'))
  model3.add(Dropout(0.4))
  model3.add(Dense(4096,activation='relu',name='FC_Layer3'))
  model3.add(Dropout(0.4))
  model3.add(Dense(1000,activation='relu',name='Out_Layer'))
  model3.add(Dense(10,activation='softmax',name='Out_Layer_2'))
  model3.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001),loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])
  model3.fit(MI_X_Train,MI_Y_Train, validation_split=0.2, epochs=10)
  return model3

Tuner=kt.Hyperband(model_Builder,objective='val_accuracy',directory='Asad',project_name='TUNER')
Early_stp=keras.callbacks.EarlyStopping(monitor='val_loss',patience=5)

Tuner.search(MI_X_Train,MI_Y_Train,epochs=10,validation_split=0.2,verbose=2,callbacks=[Early_stp])

best_Model=Tuner.get_best_models(1)[0]
best_Model.summary()

best_hps=Tuner.get_best_hyperparameters(1)[0]
new_Model=Tuner.hypermodel.build(best_hps)
history=new_Model.fit(MI_X_Train,MI_Y_Train,epochs=10,validation_split=0.2)

a,b=new_Model.evaluate(MI_X_Test,MI_Y_Test)
print(f'LOSS : {a}')
print(f'ACCURACY : {b}')

predictions = new_Model.predict(MI_X_Test)
testing=6
plt.imshow(MI_X_Test[testing])
p=predictions[testing]
print(np.argmax(predictions[testing]))
print(MI_Y_Test[testing])